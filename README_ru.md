[![en](https://img.shields.io/badge/lang-ru-green.svg)](README.md)

# Хранилище данных  и ETL-пайплайн

## Описание проекта

Этот проект извлекает сырые данные из оперативной базы данных, обрабатывает их через транзитные слои и загружает в хранилище данных для бизнес-аналитики и построения отчетов. Вся инфраструктура полностью контейнеризирована с использованием Docker Compose.

### Стек технологий

-   **База данных:** PostgreSQL 15
    
-   **Управление:** Apache Airflow 2.8
    
-   **Визуализация:** Metabase
    
-   **Инфраструктура:** Docker, Docker Compose
    
-   **Языки:** Python 3, SQL, Bash
    

----------

## Архитектура и ключевые решения

### 1. Схемы (Schemas)

Использование логических схем в экосистеме PostgreSQL внутри единой базы данных DWH.

-   Создание отдельных физических баз данных в Postgres требует использования расширения `postgres_fdw` для кросс-базовых запросов, что увеличивает сетевую нагрузку и сильно снижает производительность. Использование схем обеспечивает требуемое логическое разделение слоев, позволяя при этом выполнять высокоскоростные нативные SQL-трансформации.
    

### 2. Инкрементальная загрузка и Идемпотентность

-   Данные извлекаются из базы-источника в слой MRR с использованием метода **High Water Mark**. В Airflow `PythonOperator` обращается к таблице `dwh.high_water_mark` и забирает из источника только новые или обновленные записи о продажах.
    
-   Транзитные слои (`mrr`, `stg`) строго очищаются в начале каждого запуска для предотвращения дублирования данных.
    
-   Финальная загрузка в слой DWH использует 
`INSERT ... ON CONFLICT DO UPDATE`, что гарантирует идемпотентность и позволяет безопасно перезапускать пайплайн в любой момент.
    

### 3. Качество данных

Вместо бесследного удаления невалидных данных на этапе STG, реализован паттерн **Dead Letter Queue**.

-   Продажи с отрицательным или нулевым количеством (`qty <= 0`) перенаправляются в специальную таблицу `stg.rejected_sales` для аудита данных, что гарантирует отсутствие скрытых потерь транзакций.
    

### 4. Обработчики событий и Логирование

Требование по реализации «Event Handlers» было адаптировано под  стандарты экосистемы Airflow с использованием **Callbacks** (`on_success_callback`, `on_failure_callback`).

-   Если DAG падает с ошибкой, функция-коллбек перехватывает исключение Python и записывает точный текст ошибки, временную метку и статус напрямую в таблицу `dwh.etl_logs`.
    

### 5. Независимость от BI-платформы

Чтобы обойти строгие лицензионные ограничения Microsoft Power BI (которые блокируют локальное тестирование из-за требования корпоративной почты), непосредственно в сети Docker был развернут **Metabase**. Схема "Звезда" (Star Schema) полностью реализована на уровне DWH, что доказывает универсальность модели данных и её независимость от конкретного BI-инструмента.

----------

## Как запустить проект

### Шаг 1: Запуск инфраструктуры

Склонируйте репозиторий и запустите Docker-контейнеры. Скрипты инициализации (`init_source.sql` и `init_dwh.sql`) автоматически монтируются и выполняются в Postgres при старте.

Запущенные сервисы: `pg_source` (5432), `pg_dwh` (5433), `airflow` (8080), `metabase` (3000).

### Шаг 2: Настройка подключений Airflow

1.  Откройте интерфейс Airflow: http://localhost:8080 (Учетные данные: `admin` / `admin`).
    
2.  Перейдите в **Admin -> Connections** и добавьте два подключения Postgres:
    

**Conn Id:** `pg_source_conn`

-   **Host:** `pg_source`
    
-   **Port:** `5432`
    
-   **Schema:** `operational_db`
    
-   **Login:** `admin`
    
-   **Password:** `password`
    

**Conn Id:** `pg_dwh_conn`

-   **Host:** `pg_dwh`
    
-   **Port:** `5432`
    
-   **Schema:** `data_warehouse`
    
-   **Login:** `admin`
    
-   **Password:** `password`
    

### Шаг 3: Запуск ETL-пайплайна

1.  В интерфейсе Airflow найдите DAG `mrr_stg_dwh_pipeline`.
    
2.  Снимите DAG с паузы и запустите его вручную.
    
3.  После завершения работы пайплайна вы можете проверить логи выполнения в базе данных:

SQL

```
SELECT * FROM dwh.etl_logs ORDER BY execution_time DESC;
```
    

### Шаг 4: Бизнес-логика и хранимая процедура

Хранимая процедура использует явные курсоры и блок `TRY/CATCH` для расчета бонусных баллов лояльности на основе количества покупок и обновляет таблицу фактов. Чтобы протестировать её работу, выполните эту SQL-команду в базе данных `pg_dwh`:

SQL

```
CALL dwh.process_sales_loyalty();
```

### Шаг 5: Просмотр дашборда

1.  Откройте Metabase: http://localhost:3000.
    
2.  Подключите его к базе данных `pg_dwh` (Host: `pg_dwh`, Port: `5432`, Database: `data_warehouse`).
    
3.  Постройте дашборды, используя таблицы из схемы `dwh`.
    

----------

## Скриншоты

### Дашборд (пример)

![Dashboard](assets/dashboard_example.png)
